{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Bloom_filters as BF\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yinzhema/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yinzhema/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_classification_df=pd.read_csv('Webpages_Classification_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_classification_df.loc[web_classification_df['label']=='good',['label']]=0\n",
    "web_classification_df.loc[web_classification_df['label']=='bad',['label']]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_classification_df=pd.concat([web_classification_df[web_classification_df['label']==0][:50000],web_classification_df[web_classification_df['label']==1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    \n",
    "    def convert_lower_case(data):\n",
    "        return data.lower()\n",
    "    def remove_stopwords_punctuations_lemmatization(data):\n",
    "        tokenizer = RegexpTokenizer('\\w+')\n",
    "        words=tokenizer.tokenize(data)\n",
    "        return ' '.join([lemmatizer.lemmatize(word) for word in words if word not in stop_words])\n",
    "    \n",
    "    data=convert_lower_case(data)\n",
    "    data=remove_stopwords_punctuations_lemmatization(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 380.76it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 381.27it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 378.45it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 379.10it/s]\n",
      "100%|██████████| 10000/10000 [00:26<00:00, 378.74it/s]\n",
      "100%|██████████| 27253/27253 [02:25<00:00, 187.70it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "def experiment(df):\n",
    "    df['cleaned_content']=df['content'].progress_apply(lambda x:text_clean(x))\n",
    "    return df\n",
    "if __name__ == \"__main__\" :\n",
    "    p=multiprocessing.Pool(processes=6)\n",
    "    dfs=p.map(experiment,[web_classification_df.iloc[:10000,:],web_classification_df.iloc[10000:20000,:],\n",
    "                         web_classification_df.iloc[20000:30000,:],web_classification_df.iloc[30000:40000,:],\n",
    "                         web_classification_df.iloc[40000:50000,:],web_classification_df.iloc[50000:,:]])\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          named charged particle manly aspect francis ga...\n",
       "1          filipino field betatron criticized defense pro...\n",
       "2          took cognitivism whose adherent argue overall ...\n",
       "4          levant also monsignor george 1800 list respect...\n",
       "5          signal territorial jurisdiction common largest...\n",
       "                                 ...                        \n",
       "1199725    feces niggaz meatrack german inthebuff assassi...\n",
       "1199728    bast buried noonan sexed babe piccaninny lovep...\n",
       "1199827    backdoor hindoo firing coitus teste nittit pus...\n",
       "1199859    biatch sexhound mam wuss roach lactate bulldyk...\n",
       "1199910    shitola heeb pussypounder spigotty yellowman c...\n",
       "Name: cleaned_content, Length: 77253, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_classification_df=pd.concat(dfs)\n",
    "web_classification_df['cleaned_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'named charged particle manly aspect francis galton theory general relativity make several specific prediction hesitated edinburgh prolog could compete heavenly body protocol kamakura shogunate repelled mongol invasion 1274 1281 costume carrying high data park meteorological agency part 1905 egypt medium industry world leader enzyme product union included oral trial presumption innocence particular pheasant grey mcgraw hill stand comedy coptic catholic il 10 chicago cityscape chicago cook county majority logic component learned scrollbars matching onplaying removechild 97 evaluate nodetype blur n x substr evalerror division history string indexof ontoggle onsearch doe nan start loop onselect medium equal max_value toprecision firstchild getelementsbytagnamens n onchange onfocusout type javascript equal type javascript operator match var onstorage var onseeking const hasattributens 97 bitwise tofixed'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_classification_df['cleaned_content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model=TfidfVectorizer(ngram_range=(1,2),max_features=100)\n",
    "tfidf_matrix=tfidf_model.fit_transform(web_classification_df['cleaned_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534987</td>\n",
       "      <td>0.138947</td>\n",
       "      <td>0.138947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181037</td>\n",
       "      <td>0.148904</td>\n",
       "      <td>0.437008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77248</td>\n",
       "      <td>0.059266</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>0.629482</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049137</td>\n",
       "      <td>0.048226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101648</td>\n",
       "      <td>0.069445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097852</td>\n",
       "      <td>0.088048</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.135460</td>\n",
       "      <td>0.135460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77249</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524256</td>\n",
       "      <td>0.057998</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>0.041099</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202125</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>0.049746</td>\n",
       "      <td>0.041695</td>\n",
       "      <td>0.056277</td>\n",
       "      <td>0.111120</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.024412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77250</td>\n",
       "      <td>0.062881</td>\n",
       "      <td>0.051720</td>\n",
       "      <td>0.364294</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>0.076751</td>\n",
       "      <td>0.052271</td>\n",
       "      <td>0.033764</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161771</td>\n",
       "      <td>0.073680</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093418</td>\n",
       "      <td>0.207514</td>\n",
       "      <td>0.161687</td>\n",
       "      <td>0.161687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77251</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.026156</td>\n",
       "      <td>0.521991</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.052869</td>\n",
       "      <td>0.068301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163623</td>\n",
       "      <td>0.130417</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>0.052504</td>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.139926</td>\n",
       "      <td>0.127196</td>\n",
       "      <td>0.127196</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397865</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>0.059526</td>\n",
       "      <td>0.048804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063215</td>\n",
       "      <td>0.058790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235571</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097189</td>\n",
       "      <td>0.087452</td>\n",
       "      <td>0.226637</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.058376</td>\n",
       "      <td>0.056904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77253 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.000000  0.000000  0.230675  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.243167  0.000000  0.352191  0.000000  0.000000  0.000000  0.197871   \n",
       "2      0.181037  0.148904  0.437008  0.000000  0.183069  0.000000  0.294628   \n",
       "3      0.000000  0.000000  0.274056  0.000000  0.287015  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.589654  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77248  0.059266  0.194987  0.629482  0.090741  0.000000  0.049137  0.048226   \n",
       "77249  0.025254  0.000000  0.524256  0.057998  0.025537  0.041875  0.041099   \n",
       "77250  0.062881  0.051720  0.364294  0.096275  0.000000  0.052134  0.076751   \n",
       "77251  0.031800  0.026156  0.521991  0.024344  0.064315  0.052731  0.051753   \n",
       "77252  0.000000  0.000000  0.397865  0.045063  0.059526  0.048804  0.000000   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.273160  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  ...  0.000000  0.106064  0.000000   \n",
       "3      0.000000  0.000000  0.000000  ...  0.324530  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.000000  0.357781  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77248  0.000000  0.000000  0.059191  ...  0.101648  0.069445  0.000000   \n",
       "77249  0.020992  0.054240  0.000000  ...  0.202125  0.103568  0.049746   \n",
       "77250  0.052271  0.033764  0.062801  ...  0.161771  0.073680  0.030967   \n",
       "77251  0.052869  0.068301  0.000000  ...  0.163623  0.130417  0.062643   \n",
       "77252  0.000000  0.063215  0.058790  ...  0.235571  0.068974  0.000000   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "0      0.000000  0.000000  0.262801  0.000000  0.000000  0.000000  0.000000  \n",
       "1      0.000000  0.000000  0.534987  0.138947  0.138947  0.000000  0.000000  \n",
       "2      0.000000  0.134478  0.099574  0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "77248  0.097852  0.088048  0.228184  0.135460  0.135460  0.000000  0.057292  \n",
       "77249  0.041695  0.056277  0.111120  0.187590  0.187590  0.025044  0.024412  \n",
       "77250  0.000000  0.093418  0.207514  0.161687  0.161687  0.000000  0.030393  \n",
       "77251  0.052504  0.070866  0.139926  0.127196  0.127196  0.031536  0.000000  \n",
       "77252  0.097189  0.087452  0.226637  0.168178  0.168178  0.058376  0.056904  \n",
       "\n",
       "[77253 rows x 100 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set=pd.DataFrame.sparse.from_spmatrix(tfidf_matrix)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20',\n",
       " '23',\n",
       " '97',\n",
       " '97 97',\n",
       " '97 script',\n",
       " 'abc',\n",
       " 'age',\n",
       " 'alert',\n",
       " 'butt',\n",
       " 'case',\n",
       " 'closed',\n",
       " 'code',\n",
       " 'code code',\n",
       " 'comment',\n",
       " 'concat',\n",
       " 'condition',\n",
       " 'confirm',\n",
       " 'const',\n",
       " 'date',\n",
       " 'division',\n",
       " 'document',\n",
       " 'doe',\n",
       " 'equal',\n",
       " 'eval',\n",
       " 'execute',\n",
       " 'executed',\n",
       " 'find',\n",
       " 'firstname',\n",
       " 'firstname john',\n",
       " 'focus',\n",
       " 'function',\n",
       " 'german',\n",
       " 'global',\n",
       " 'greater',\n",
       " 'history',\n",
       " 'indexof',\n",
       " 'input',\n",
       " 'javascript',\n",
       " 'john',\n",
       " 'lastindexof',\n",
       " 'lastname',\n",
       " 'le',\n",
       " 'left',\n",
       " 'let',\n",
       " 'line',\n",
       " 'location',\n",
       " 'log',\n",
       " 'logical',\n",
       " 'loop',\n",
       " 'matching',\n",
       " 'medium',\n",
       " 'method',\n",
       " 'multiple',\n",
       " 'myscript',\n",
       " 'myscript script',\n",
       " 'name',\n",
       " 'number',\n",
       " 'object',\n",
       " 'onabort',\n",
       " 'onerror',\n",
       " 'open',\n",
       " 'operation',\n",
       " 'operator',\n",
       " 'pattern',\n",
       " 'perform',\n",
       " 'person',\n",
       " 'pi',\n",
       " 'position',\n",
       " 'prompt',\n",
       " 'right',\n",
       " 'script',\n",
       " 'script 97',\n",
       " 'script code',\n",
       " 'scrollbars',\n",
       " 'search',\n",
       " 'self',\n",
       " 'setinterval',\n",
       " 'settimeout',\n",
       " 'shift',\n",
       " 'single',\n",
       " 'slice',\n",
       " 'src',\n",
       " 'src myscript',\n",
       " 'statement',\n",
       " 'string',\n",
       " 'textarea',\n",
       " 'top',\n",
       " 'tostring',\n",
       " 'true',\n",
       " 'type',\n",
       " 'type javascript',\n",
       " 'unescape',\n",
       " 'user',\n",
       " 'value',\n",
       " 'valueof',\n",
       " 'var',\n",
       " 'window',\n",
       " 'window open',\n",
       " 'within',\n",
       " 'xxx']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534987</td>\n",
       "      <td>0.138947</td>\n",
       "      <td>0.138947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181037</td>\n",
       "      <td>0.148904</td>\n",
       "      <td>0.437008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.589654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77248</td>\n",
       "      <td>0.059266</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>0.629482</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049137</td>\n",
       "      <td>0.048226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097852</td>\n",
       "      <td>0.088048</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.135460</td>\n",
       "      <td>0.135460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77249</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.524256</td>\n",
       "      <td>0.057998</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>0.041099</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103568</td>\n",
       "      <td>0.049746</td>\n",
       "      <td>0.041695</td>\n",
       "      <td>0.056277</td>\n",
       "      <td>0.111120</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77250</td>\n",
       "      <td>0.062881</td>\n",
       "      <td>0.051720</td>\n",
       "      <td>0.364294</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>0.076751</td>\n",
       "      <td>0.052271</td>\n",
       "      <td>0.033764</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073680</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093418</td>\n",
       "      <td>0.207514</td>\n",
       "      <td>0.161687</td>\n",
       "      <td>0.161687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77251</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.026156</td>\n",
       "      <td>0.521991</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.052869</td>\n",
       "      <td>0.068301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130417</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>0.052504</td>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.139926</td>\n",
       "      <td>0.127196</td>\n",
       "      <td>0.127196</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397865</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>0.059526</td>\n",
       "      <td>0.048804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063215</td>\n",
       "      <td>0.058790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097189</td>\n",
       "      <td>0.087452</td>\n",
       "      <td>0.226637</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.168178</td>\n",
       "      <td>0.058376</td>\n",
       "      <td>0.056904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77253 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.000000  0.000000  0.230675  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.243167  0.000000  0.352191  0.000000  0.000000  0.000000  0.197871   \n",
       "2      0.181037  0.148904  0.437008  0.000000  0.183069  0.000000  0.294628   \n",
       "3      0.000000  0.000000  0.274056  0.000000  0.287015  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.589654  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "77248  0.059266  0.194987  0.629482  0.090741  0.000000  0.049137  0.048226   \n",
       "77249  0.025254  0.000000  0.524256  0.057998  0.025537  0.041875  0.041099   \n",
       "77250  0.062881  0.051720  0.364294  0.096275  0.000000  0.052134  0.076751   \n",
       "77251  0.031800  0.026156  0.521991  0.024344  0.064315  0.052731  0.051753   \n",
       "77252  0.000000  0.000000  0.397865  0.045063  0.059526  0.048804  0.000000   \n",
       "\n",
       "              7         8         9  ...        91        92        93  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  ...  0.106064  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.357781  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "77248  0.000000  0.000000  0.059191  ...  0.069445  0.000000  0.097852   \n",
       "77249  0.020992  0.054240  0.000000  ...  0.103568  0.049746  0.041695   \n",
       "77250  0.052271  0.033764  0.062801  ...  0.073680  0.030967  0.000000   \n",
       "77251  0.052869  0.068301  0.000000  ...  0.130417  0.062643  0.052504   \n",
       "77252  0.000000  0.063215  0.058790  ...  0.068974  0.000000  0.097189   \n",
       "\n",
       "             94        95        96        97        98        99  Label  \n",
       "0      0.000000  0.262801  0.000000  0.000000  0.000000  0.000000      0  \n",
       "1      0.000000  0.534987  0.138947  0.138947  0.000000  0.000000      0  \n",
       "2      0.134478  0.099574  0.000000  0.000000  0.000000  0.000000      0  \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      0  \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "77248  0.088048  0.228184  0.135460  0.135460  0.000000  0.057292      1  \n",
       "77249  0.056277  0.111120  0.187590  0.187590  0.025044  0.024412      1  \n",
       "77250  0.093418  0.207514  0.161687  0.161687  0.000000  0.030393      1  \n",
       "77251  0.070866  0.139926  0.127196  0.127196  0.031536  0.000000      1  \n",
       "77252  0.087452  0.226637  0.168178  0.168178  0.058376  0.056904      1  \n",
       "\n",
       "[77253 rows x 101 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label']=web_classification_df.reset_index()['label']\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20',\n",
       " '23',\n",
       " '97',\n",
       " '97 97',\n",
       " '97 script',\n",
       " 'abc',\n",
       " 'age',\n",
       " 'alert',\n",
       " 'butt',\n",
       " 'case',\n",
       " 'closed',\n",
       " 'code',\n",
       " 'code code',\n",
       " 'comment',\n",
       " 'concat',\n",
       " 'condition',\n",
       " 'confirm',\n",
       " 'const',\n",
       " 'date',\n",
       " 'division',\n",
       " 'document',\n",
       " 'doe',\n",
       " 'equal',\n",
       " 'eval',\n",
       " 'execute',\n",
       " 'executed',\n",
       " 'find',\n",
       " 'firstname',\n",
       " 'firstname john',\n",
       " 'focus',\n",
       " 'function',\n",
       " 'german',\n",
       " 'global',\n",
       " 'greater',\n",
       " 'history',\n",
       " 'indexof',\n",
       " 'input',\n",
       " 'javascript',\n",
       " 'john',\n",
       " 'lastindexof',\n",
       " 'lastname',\n",
       " 'le',\n",
       " 'left',\n",
       " 'let',\n",
       " 'line',\n",
       " 'location',\n",
       " 'log',\n",
       " 'logical',\n",
       " 'loop',\n",
       " 'matching',\n",
       " 'medium',\n",
       " 'method',\n",
       " 'multiple',\n",
       " 'myscript',\n",
       " 'myscript script',\n",
       " 'name',\n",
       " 'number',\n",
       " 'object',\n",
       " 'onabort',\n",
       " 'onerror',\n",
       " 'open',\n",
       " 'operation',\n",
       " 'operator',\n",
       " 'pattern',\n",
       " 'perform',\n",
       " 'person',\n",
       " 'pi',\n",
       " 'position',\n",
       " 'prompt',\n",
       " 'right',\n",
       " 'script',\n",
       " 'script 97',\n",
       " 'script code',\n",
       " 'scrollbars',\n",
       " 'search',\n",
       " 'self',\n",
       " 'setinterval',\n",
       " 'settimeout',\n",
       " 'shift',\n",
       " 'single',\n",
       " 'slice',\n",
       " 'src',\n",
       " 'src myscript',\n",
       " 'statement',\n",
       " 'string',\n",
       " 'textarea',\n",
       " 'top',\n",
       " 'tostring',\n",
       " 'true',\n",
       " 'type',\n",
       " 'type javascript',\n",
       " 'unescape',\n",
       " 'user',\n",
       " 'value',\n",
       " 'valueof',\n",
       " 'var',\n",
       " 'window',\n",
       " 'window open',\n",
       " 'within',\n",
       " 'xxx']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_model=CountVectorizer(ngram_range=(1,2),max_features=100)\n",
    "bow_result=bow_model.fit_transform(web_classification_df['cleaned_content'])\n",
    "\n",
    "bow_result=pd.DataFrame.sparse.from_spmatrix(bow_result)\n",
    "\n",
    "bow_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_result['Label']=web_classification_df.reset_index()['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_x, bow_test_x, bow_train_y, bow_test_y=train_test_split(bow_result.iloc[:,:-1],bow_result.iloc[:,-1],train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://www.hopstudios.com/nep/</td>\n",
       "      <td>30</td>\n",
       "      <td>4.46.248.66</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>yes</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Dome. grant regenerates it. the signal is retr...</td>\n",
       "      <td>0</td>\n",
       "      <td>dome grant regenerates signal retransmitted pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://www.transensexkontakte.com/</td>\n",
       "      <td>34</td>\n",
       "      <td>78.39.167.39</td>\n",
       "      <td>Iran</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>441.0</td>\n",
       "      <td>255.78</td>\n",
       "      <td>crack-whore dong cumqueen cameltoe god kigger ...</td>\n",
       "      <td>1</td>\n",
       "      <td>crack whore dong cumqueen cameltoe god kigger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://www.tn.gov.in/tsunami/</td>\n",
       "      <td>29</td>\n",
       "      <td>193.235.142.16</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>gov.in</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>yes</td>\n",
       "      <td>69.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>hiv kumming hostage lactate screw sluts shitfu...</td>\n",
       "      <td>0</td>\n",
       "      <td>hiv kumming hostage lactate screw slut shitfuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://www.oconnellfuneralhomes.com/</td>\n",
       "      <td>36</td>\n",
       "      <td>182.146.117.106</td>\n",
       "      <td>China</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>yes</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Of subscription tours, and regulations are aff...</td>\n",
       "      <td>0</td>\n",
       "      <td>subscription tour regulation affecting current...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://ipinferno.blogspot.com/</td>\n",
       "      <td>30</td>\n",
       "      <td>168.4.105.108</td>\n",
       "      <td>United States</td>\n",
       "      <td>blogspot.com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Eguzon dam, \"any agency of the following peace...</td>\n",
       "      <td>0</td>\n",
       "      <td>eguzon dam agency following peace settlement d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23171</td>\n",
       "      <td>http://www.lawgazettejobs.co.uk</td>\n",
       "      <td>31</td>\n",
       "      <td>90.91.46.25</td>\n",
       "      <td>France</td>\n",
       "      <td>co.uk</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>130.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Have pledged ethical issue on hoy's definition...</td>\n",
       "      <td>0</td>\n",
       "      <td>pledged ethical issue hoy definition likewise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23172</td>\n",
       "      <td>http://www.culturekiosque.com/opera/</td>\n",
       "      <td>36</td>\n",
       "      <td>125.16.120.215</td>\n",
       "      <td>India</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Influences that and mortality that only cater ...</td>\n",
       "      <td>0</td>\n",
       "      <td>influence mortality cater 1977 continental pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23173</td>\n",
       "      <td>http://www.dolphin-designs.com/</td>\n",
       "      <td>31</td>\n",
       "      <td>70.74.66.219</td>\n",
       "      <td>Canada</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>187.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Death rate of rivers. rivers help. Publication...</td>\n",
       "      <td>0</td>\n",
       "      <td>death rate river river help publication soluti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23174</td>\n",
       "      <td>http://www.carolslinks.com/</td>\n",
       "      <td>27</td>\n",
       "      <td>108.68.43.218</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>shagging enema drunken shitola fucktard crotch...</td>\n",
       "      <td>1</td>\n",
       "      <td>shagging enema drunken shitola fucktard crotch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23175</td>\n",
       "      <td>http://www.fdaa.com/</td>\n",
       "      <td>20</td>\n",
       "      <td>47.48.57.167</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Metres (420 argentina vowed not to. Yugoslav n...</td>\n",
       "      <td>0</td>\n",
       "      <td>metre 420 argentina vowed yugoslav nationalist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23176 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        url  url_len           ip_add  \\\n",
       "0            http://www.hopstudios.com/nep/       30      4.46.248.66   \n",
       "1        http://www.transensexkontakte.com/       34     78.39.167.39   \n",
       "2             http://www.tn.gov.in/tsunami/       29   193.235.142.16   \n",
       "3      http://www.oconnellfuneralhomes.com/       36  182.146.117.106   \n",
       "4            http://ipinferno.blogspot.com/       30    168.4.105.108   \n",
       "...                                     ...      ...              ...   \n",
       "23171       http://www.lawgazettejobs.co.uk       31      90.91.46.25   \n",
       "23172  http://www.culturekiosque.com/opera/       36   125.16.120.215   \n",
       "23173       http://www.dolphin-designs.com/       31     70.74.66.219   \n",
       "23174           http://www.carolslinks.com/       27    108.68.43.218   \n",
       "23175                  http://www.fdaa.com/       20     47.48.57.167   \n",
       "\n",
       "             geo_loc           tld      who_is https  js_len  js_obf_len  \\\n",
       "0      United States           com  incomplete   yes   129.0        0.00   \n",
       "1               Iran           com  incomplete    no   441.0      255.78   \n",
       "2             Sweden        gov.in  incomplete   yes    69.5        0.00   \n",
       "3              China           com  incomplete   yes   159.0        0.00   \n",
       "4      United States  blogspot.com    complete   yes   153.0        0.00   \n",
       "...              ...           ...         ...   ...     ...         ...   \n",
       "23171         France         co.uk    complete   yes   130.5        0.00   \n",
       "23172          India           com    complete   yes   109.0        0.00   \n",
       "23173         Canada           com    complete   yes   187.5        0.00   \n",
       "23174  United States           com  incomplete    no     0.0        0.00   \n",
       "23175  United States           com    complete   yes    43.5        0.00   \n",
       "\n",
       "                                                 content  label  \\\n",
       "0      Dome. grant regenerates it. the signal is retr...      0   \n",
       "1      crack-whore dong cumqueen cameltoe god kigger ...      1   \n",
       "2      hiv kumming hostage lactate screw sluts shitfu...      0   \n",
       "3      Of subscription tours, and regulations are aff...      0   \n",
       "4      Eguzon dam, \"any agency of the following peace...      0   \n",
       "...                                                  ...    ...   \n",
       "23171  Have pledged ethical issue on hoy's definition...      0   \n",
       "23172  Influences that and mortality that only cater ...      0   \n",
       "23173  Death rate of rivers. rivers help. Publication...      0   \n",
       "23174  shagging enema drunken shitola fucktard crotch...      1   \n",
       "23175  Metres (420 argentina vowed not to. Yugoslav n...      0   \n",
       "\n",
       "                                         cleaned_content  \n",
       "0      dome grant regenerates signal retransmitted pr...  \n",
       "1      crack whore dong cumqueen cameltoe god kigger ...  \n",
       "2      hiv kumming hostage lactate screw slut shitfuc...  \n",
       "3      subscription tour regulation affecting current...  \n",
       "4      eguzon dam agency following peace settlement d...  \n",
       "...                                                  ...  \n",
       "23171  pledged ethical issue hoy definition likewise ...  \n",
       "23172  influence mortality cater 1977 continental pra...  \n",
       "23173  death rate river river help publication soluti...  \n",
       "23174  shagging enema drunken shitola fucktard crotch...  \n",
       "23175  metre 420 argentina vowed yugoslav nationalist...  \n",
       "\n",
       "[23176 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_input=web_classification_df.iloc[bow_test_x.index.tolist(),:].reset_index()\n",
    "bow_input=bow_input.drop(columns=['index','Unnamed: 0'])\n",
    "bow_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54073</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54074</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54075</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54077 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1   2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  \\\n",
       "0      0  0   8  1  0  0  0  0  0  0  ...   2   0   0   1   4   2   2   0   0   \n",
       "1      0  1   9  1  0  1  0  1  0  0  ...   1   0   0   1   3   0   0   0   0   \n",
       "2      0  0  10  0  0  0  0  2  0  0  ...   5   0   0   0   4   3   3   0   1   \n",
       "3      2  2  34  1  2  1  3  2  2  1  ...   7   0   2   1   7   7   7   1   2   \n",
       "4      0  1  10  2  0  1  0  0  0  0  ...   2   0   1   0   1   1   1   0   1   \n",
       "...   .. ..  .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "54072  0  0   4  0  0  0  0  0  0  0  ...   0   0   1   1   0   1   1   0   0   \n",
       "54073  0  2  15  2  1  0  0  2  3  0  ...   7   0   1   0   3   6   6   1   1   \n",
       "54074  0  1   7  0  0  0  0  0  0  0  ...   3   0   0   0   7   4   4   0   0   \n",
       "54075  1  0   6  0  0  0  1  2  0  0  ...   1   0   1   1   3   1   1   1   1   \n",
       "54076  0  0  15  2  1  1  0  0  0  1  ...   2   0   0   1   2   0   0   0   0   \n",
       "\n",
       "       Label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  \n",
       "...      ...  \n",
       "54072      0  \n",
       "54073      1  \n",
       "54074      0  \n",
       "54075      0  \n",
       "54076      0  \n",
       "\n",
       "[54077 rows x 101 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train=bow_train_x.reset_index().drop(columns=['index'])\n",
    "bow_train['Label']=bow_train_y.reset_index().drop(columns=['index'])['Label']\n",
    "bow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23176 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1   2  3  4  5  6  7  8  9  ...  91  92  93  94  95  96  97  98  99  \\\n",
       "0      1  1   8  0  0  0  1  1  0  0  ...   2   0   1   0   3   3   3   0   0   \n",
       "1      1  0  26  0  0  2  2  2  0  1  ...   6   0   0   3  10   6   6   0   0   \n",
       "2      0  0   5  0  0  0  0  0  1  0  ...   1   0   0   0   0   1   1   0   0   \n",
       "3      1  1   4  1  1  0  1  0  0  0  ...   2   0   2   1   3   2   2   0   0   \n",
       "4      0  0  13  1  2  0  1  1  0  1  ...   2   0   0   1   2   3   3   0   0   \n",
       "...   .. ..  .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "23171  1  0  11  0  0  0  3  0  0  0  ...   0   0   0   1   2   1   1   2   0   \n",
       "23172  0  0   5  2  0  0  2  0  0  0  ...   0   0   0   0   3   2   2   0   0   \n",
       "23173  1  0   8  0  1  0  1  1  0  0  ...   1   1   0   0   6   4   4   0   1   \n",
       "23174  0  0   0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   0   0   1   \n",
       "23175  0  0   0  0  0  0  0  0  0  0  ...   0   0   0   0   0   1   1   0   0   \n",
       "\n",
       "       Label  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "23171      0  \n",
       "23172      0  \n",
       "23173      0  \n",
       "23174      1  \n",
       "23175      0  \n",
       "\n",
       "[23176 rows x 101 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test=bow_test_x.reset_index().drop(columns=['index'])\n",
    "bow_test['Label']=bow_test_y.reset_index().drop(columns=['index'])['Label']\n",
    "bow_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split for TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_x, tfidf_test_x, tfidf_train_y, tfidf_test_y=train_test_split(training_set.iloc[:,:-1],training_set.iloc[:,-1],train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://www.ass-smother.com/</td>\n",
       "      <td>27</td>\n",
       "      <td>159.9.115.25</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>yes</td>\n",
       "      <td>849.6</td>\n",
       "      <td>492.768</td>\n",
       "      <td>kumquat redneck bountybar crackwhore anal abbo...</td>\n",
       "      <td>1</td>\n",
       "      <td>kumquat redneck bountybar crackwhore anal abbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://www.carolineose.com/</td>\n",
       "      <td>27</td>\n",
       "      <td>11.35.178.184</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>honk urinate fight scum bible deposit fannyfuc...</td>\n",
       "      <td>1</td>\n",
       "      <td>honk urinate fight scum bible deposit fannyfuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://www.cherryboys.net/club_trip/</td>\n",
       "      <td>36</td>\n",
       "      <td>90.145.23.162</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>net</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>567.9</td>\n",
       "      <td>386.172</td>\n",
       "      <td>masturbating niggard's sweetness piss boobs in...</td>\n",
       "      <td>1</td>\n",
       "      <td>masturbating niggard sweetness piss boob inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://www.teenreads.com/authors/au-almond-dav...</td>\n",
       "      <td>52</td>\n",
       "      <td>77.16.139.93</td>\n",
       "      <td>Norway</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Achieve this underway, in an. Year round suffi...</td>\n",
       "      <td>0</td>\n",
       "      <td>achieve underway year round sufficient evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://www.logix.com/</td>\n",
       "      <td>21</td>\n",
       "      <td>152.243.84.77</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Become brazil's force with. Albeit unusual fas...</td>\n",
       "      <td>0</td>\n",
       "      <td>become brazil force albeit unusual fashion sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23171</td>\n",
       "      <td>http://www.billowfuneralhomes.com/</td>\n",
       "      <td>34</td>\n",
       "      <td>46.226.72.47</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>66.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Situation has particular circumstances and was...</td>\n",
       "      <td>0</td>\n",
       "      <td>situation particular circumstance formerly wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23172</td>\n",
       "      <td>http://www.jennifer-lopez-pictures.com/</td>\n",
       "      <td>39</td>\n",
       "      <td>169.235.227.87</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>578.7</td>\n",
       "      <td>295.137</td>\n",
       "      <td>goddammit sonofabitch banging thicklips mickey...</td>\n",
       "      <td>1</td>\n",
       "      <td>goddammit sonofabitch banging thicklips mickey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23173</td>\n",
       "      <td>http://banksia.scoutsqld.com.au/</td>\n",
       "      <td>32</td>\n",
       "      <td>168.20.193.233</td>\n",
       "      <td>United States</td>\n",
       "      <td>com.au</td>\n",
       "      <td>complete</td>\n",
       "      <td>no</td>\n",
       "      <td>97.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Students. it was prudence, exercised through m...</td>\n",
       "      <td>0</td>\n",
       "      <td>student prudence exercised moderation caution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23174</td>\n",
       "      <td>http://www.isomedia.com/homes/crabapple/appleg...</td>\n",
       "      <td>54</td>\n",
       "      <td>134.40.185.32</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>111.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>92.1 males. and nouns for evaluation. That fal...</td>\n",
       "      <td>0</td>\n",
       "      <td>92 1 male noun evaluation falling unpredictabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23175</td>\n",
       "      <td>http://www.erosex.com.br</td>\n",
       "      <td>24</td>\n",
       "      <td>152.65.125.232</td>\n",
       "      <td>Norway</td>\n",
       "      <td>com.br</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>797.4</td>\n",
       "      <td>733.608</td>\n",
       "      <td>tantra spick limey joint tampon kum fuckedup u...</td>\n",
       "      <td>1</td>\n",
       "      <td>tantra spick limey joint tampon kum fuckedup u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23176 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  url_len  \\\n",
       "0                            http://www.ass-smother.com/       27   \n",
       "1                            http://www.carolineose.com/       27   \n",
       "2                   http://www.cherryboys.net/club_trip/       36   \n",
       "3      http://www.teenreads.com/authors/au-almond-dav...       52   \n",
       "4                                  http://www.logix.com/       21   \n",
       "...                                                  ...      ...   \n",
       "23171                 http://www.billowfuneralhomes.com/       34   \n",
       "23172            http://www.jennifer-lopez-pictures.com/       39   \n",
       "23173                   http://banksia.scoutsqld.com.au/       32   \n",
       "23174  http://www.isomedia.com/homes/crabapple/appleg...       54   \n",
       "23175                           http://www.erosex.com.br       24   \n",
       "\n",
       "               ip_add         geo_loc     tld      who_is https  js_len  \\\n",
       "0        159.9.115.25   United States     com  incomplete   yes   849.6   \n",
       "1       11.35.178.184   United States     com  incomplete    no     0.0   \n",
       "2       90.145.23.162     Netherlands     net  incomplete    no   567.9   \n",
       "3        77.16.139.93          Norway     com    complete   yes    42.5   \n",
       "4       152.243.84.77          Brazil     com    complete   yes   124.0   \n",
       "...               ...             ...     ...         ...   ...     ...   \n",
       "23171    46.226.72.47  United Kingdom     com    complete   yes    66.5   \n",
       "23172  169.235.227.87   United States     com  incomplete    no   578.7   \n",
       "23173  168.20.193.233   United States  com.au    complete    no    97.5   \n",
       "23174   134.40.185.32   United States     com    complete   yes   111.5   \n",
       "23175  152.65.125.232          Norway  com.br  incomplete    no   797.4   \n",
       "\n",
       "       js_obf_len                                            content  label  \\\n",
       "0         492.768  kumquat redneck bountybar crackwhore anal abbo...      1   \n",
       "1           0.000  honk urinate fight scum bible deposit fannyfuc...      1   \n",
       "2         386.172  masturbating niggard's sweetness piss boobs in...      1   \n",
       "3           0.000  Achieve this underway, in an. Year round suffi...      0   \n",
       "4           0.000  Become brazil's force with. Albeit unusual fas...      0   \n",
       "...           ...                                                ...    ...   \n",
       "23171       0.000  Situation has particular circumstances and was...      0   \n",
       "23172     295.137  goddammit sonofabitch banging thicklips mickey...      1   \n",
       "23173       0.000  Students. it was prudence, exercised through m...      0   \n",
       "23174       0.000  92.1 males. and nouns for evaluation. That fal...      0   \n",
       "23175     733.608  tantra spick limey joint tampon kum fuckedup u...      1   \n",
       "\n",
       "                                         cleaned_content  \n",
       "0      kumquat redneck bountybar crackwhore anal abbo...  \n",
       "1      honk urinate fight scum bible deposit fannyfuc...  \n",
       "2      masturbating niggard sweetness piss boob inter...  \n",
       "3      achieve underway year round sufficient evidenc...  \n",
       "4      become brazil force albeit unusual fashion sty...  \n",
       "...                                                  ...  \n",
       "23171  situation particular circumstance formerly wil...  \n",
       "23172  goddammit sonofabitch banging thicklips mickey...  \n",
       "23173  student prudence exercised moderation caution ...  \n",
       "23174  92 1 male noun evaluation falling unpredictabl...  \n",
       "23175  tantra spick limey joint tampon kum fuckedup u...  \n",
       "\n",
       "[23176 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_input=web_classification_df.iloc[tfidf_test_x.index.tolist(),:].reset_index()\n",
    "tfidf_input=tfidf_input.drop(columns=['index','Unnamed: 0'])\n",
    "tfidf_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462185</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382473</td>\n",
       "      <td>0.202160</td>\n",
       "      <td>0.267040</td>\n",
       "      <td>0.218942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.118157</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.541923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.049110</td>\n",
       "      <td>0.190336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207676</td>\n",
       "      <td>0.058189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194967</td>\n",
       "      <td>0.168789</td>\n",
       "      <td>0.168789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>0.547295</td>\n",
       "      <td>0.057855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093987</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.062823</td>\n",
       "      <td>0.081161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132832</td>\n",
       "      <td>0.037218</td>\n",
       "      <td>0.062389</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>0.187055</td>\n",
       "      <td>0.129552</td>\n",
       "      <td>0.129552</td>\n",
       "      <td>0.037474</td>\n",
       "      <td>0.073057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047088</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.500129</td>\n",
       "      <td>0.108142</td>\n",
       "      <td>0.071424</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.038316</td>\n",
       "      <td>0.039142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110349</td>\n",
       "      <td>0.046378</td>\n",
       "      <td>0.077745</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>0.142445</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>0.542450</td>\n",
       "      <td>0.122878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183435</td>\n",
       "      <td>0.183435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54073</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>0.133162</td>\n",
       "      <td>0.573187</td>\n",
       "      <td>0.041313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089485</td>\n",
       "      <td>0.043914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057955</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094852</td>\n",
       "      <td>0.106306</td>\n",
       "      <td>0.044551</td>\n",
       "      <td>0.080174</td>\n",
       "      <td>0.207777</td>\n",
       "      <td>0.092509</td>\n",
       "      <td>0.092509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084584</td>\n",
       "      <td>0.397183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.113124</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.058761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660522</td>\n",
       "      <td>0.149625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54076</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.030958</td>\n",
       "      <td>0.490626</td>\n",
       "      <td>0.086442</td>\n",
       "      <td>0.076123</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.061255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>0.227722</td>\n",
       "      <td>0.150548</td>\n",
       "      <td>0.150548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54077 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.000000  0.000000  0.462185  0.073288  0.000000  0.079371  0.000000   \n",
       "1      0.000000  0.000000  0.382473  0.202160  0.267040  0.218942  0.000000   \n",
       "2      0.118157  0.048593  0.541923  0.000000  0.000000  0.000000  0.096148   \n",
       "3      0.000000  0.031080  0.547295  0.057855  0.000000  0.093987  0.030749   \n",
       "4      0.047088  0.019365  0.500129  0.108142  0.071424  0.019520  0.038316   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "54072  0.000000  0.132022  0.542450  0.122878  0.000000  0.133079  0.000000   \n",
       "54073  0.053966  0.133162  0.573187  0.041313  0.000000  0.089485  0.043914   \n",
       "54074  0.000000  0.084584  0.397183  0.000000  0.000000  0.085261  0.000000   \n",
       "54075  0.000000  0.000000  0.660522  0.149625  0.000000  0.000000  0.000000   \n",
       "54076  0.037639  0.030958  0.490626  0.086442  0.076123  0.093617  0.061255   \n",
       "\n",
       "              7         8         9  ...        91        92        93  \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.056088  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.049110  0.190336  0.000000  ...  0.207676  0.058189  0.000000   \n",
       "3      0.062823  0.081161  0.000000  ...  0.132832  0.037218  0.062389   \n",
       "4      0.039142  0.000000  0.023514  ...  0.110349  0.046378  0.077745   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "54072  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "54073  0.000000  0.057955  0.053897  ...  0.094852  0.106306  0.044551   \n",
       "54074  0.170970  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "54075  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "54076  0.000000  0.000000  0.037591  ...  0.176412  0.000000  0.062144   \n",
       "\n",
       "             94        95        96        97        98        99  Label  \n",
       "0      0.071113  0.000000  0.000000  0.000000  0.000000  0.000000      0  \n",
       "1      0.000000  0.290493  0.000000  0.000000  0.000000  0.000000      0  \n",
       "2      0.000000  0.194967  0.168789  0.168789  0.000000  0.057111      1  \n",
       "3      0.056139  0.187055  0.129552  0.129552  0.037474  0.073057      1  \n",
       "4      0.017489  0.142445  0.174889  0.174889  0.023348  0.045519      1  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "54072  0.000000  0.000000  0.183435  0.183435  0.000000  0.000000      0  \n",
       "54073  0.080174  0.207777  0.092509  0.092509  0.000000  0.156505      1  \n",
       "54074  0.076389  0.113124  0.058761  0.058761  0.000000  0.000000      0  \n",
       "54075  0.000000  0.107501  0.000000  0.000000  0.000000  0.000000      0  \n",
       "54076  0.083876  0.227722  0.150548  0.150548  0.000000  0.000000      1  \n",
       "\n",
       "[54077 rows x 101 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train=tfidf_train_x.reset_index().drop(columns=['index'])\n",
    "tfidf_train['Label']=tfidf_train_y.reset_index().drop(columns=['index'])['Label']\n",
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036699</td>\n",
       "      <td>0.581609</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0.02256</td>\n",
       "      <td>0.036993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143774</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.066287</td>\n",
       "      <td>0.110435</td>\n",
       "      <td>0.152971</td>\n",
       "      <td>0.152971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519455</td>\n",
       "      <td>0.109825</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126075</td>\n",
       "      <td>0.070650</td>\n",
       "      <td>0.029608</td>\n",
       "      <td>0.026641</td>\n",
       "      <td>0.177539</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570886</td>\n",
       "      <td>0.113155</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.122548</td>\n",
       "      <td>0.120278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081299</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.581662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23172</td>\n",
       "      <td>0.037596</td>\n",
       "      <td>0.030923</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>0.091777</td>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.040374</td>\n",
       "      <td>0.075096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.027927</td>\n",
       "      <td>0.165427</td>\n",
       "      <td>0.171858</td>\n",
       "      <td>0.171858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613617</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.18361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23174</td>\n",
       "      <td>0.283612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342309</td>\n",
       "      <td>0.108558</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.235140</td>\n",
       "      <td>0.230782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23175</td>\n",
       "      <td>0.047335</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.548465</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.058868</td>\n",
       "      <td>0.057777</td>\n",
       "      <td>0.039348</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.023638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058615</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>0.156212</td>\n",
       "      <td>0.162286</td>\n",
       "      <td>0.162286</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.068638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23176 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3        4         5         6  \\\n",
       "0      0.000000  0.036699  0.581609  0.051236  0.02256  0.036993  0.000000   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.519455  0.109825  0.00000  0.000000  0.029184   \n",
       "3      0.000000  0.000000  0.235210  0.000000  0.00000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.570886  0.113155  0.00000  0.122548  0.120278   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "23171  0.000000  0.000000  0.581662  0.000000  0.00000  0.000000  0.000000   \n",
       "23172  0.037596  0.030923  0.562667  0.115124  0.00000  0.031170  0.091777   \n",
       "23173  0.000000  0.000000  0.613617  0.139000  0.18361  0.000000  0.000000   \n",
       "23174  0.283612  0.000000  0.342309  0.108558  0.00000  0.235140  0.230782   \n",
       "23175  0.047335  0.058400  0.548465  0.090592  0.00000  0.058868  0.057777   \n",
       "\n",
       "              7         8         9  ...        91        92        93  \\\n",
       "0      0.000000  0.023958  0.000000  ...  0.143774  0.021973  0.018417   \n",
       "1      0.000000  0.625987  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2      0.059627  0.038516  0.035820  ...  0.126075  0.070650  0.029608   \n",
       "3      0.202495  0.000000  0.000000  ...  0.142717  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.086598  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "23171  0.000000  0.000000  0.240655  ...  0.141173  0.000000  0.000000   \n",
       "23172  0.031252  0.040374  0.075096  ...  0.154184  0.000000  0.031036   \n",
       "23173  0.000000  0.000000  0.000000  ...  0.106377  0.000000  0.149893   \n",
       "23174  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "23175  0.039348  0.025417  0.023638  ...  0.138662  0.000000  0.058615   \n",
       "\n",
       "             94        95        96        97        98        99  Label  \n",
       "0      0.066287  0.110435  0.152971  0.152971  0.000000  0.043132      1  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      1  \n",
       "2      0.026641  0.177539  0.102468  0.102468  0.000000  0.034670      1  \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.235483      0  \n",
       "4      0.000000  0.081299  0.084460  0.084460  0.000000  0.142887      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "23171  0.000000  0.132534  0.000000  0.000000  0.000000  0.000000      0  \n",
       "23172  0.027927  0.165427  0.171858  0.171858  0.000000  0.072686      1  \n",
       "23173  0.000000  0.000000  0.000000  0.000000  0.000000  0.175522      0  \n",
       "23174  0.000000  0.155992  0.000000  0.000000  0.000000  0.274164      0  \n",
       "23175  0.052742  0.156212  0.162286  0.162286  0.023471  0.068638      1  \n",
       "\n",
       "[23176 rows x 101 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test=tfidf_test_x.reset_index().drop(columns=['index'])\n",
    "tfidf_test['Label']=tfidf_test_y.reset_index().drop(columns=['index'])['Label']\n",
    "tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Naive-Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1e-10, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier=MultinomialNB(alpha=1.0e-10)\n",
    "nb_classifier.fit(tfidf_train.iloc[:,:-1],tfidf_train.iloc[:,-1])\n",
    "#cross_val_score(nb_classifier,tfidf_test.iloc[:,:-1],tfidf_test.iloc[:,-1],cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_prob=nb_classifier.predict_proba(tfidf_test.iloc[:,:-1])[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_bow=MultinomialNB(alpha=1.0e-10)\n",
    "nb_classifier_bow.fit(bow_train.iloc[:,:-1],bow_train.iloc[:,-1])\n",
    "nb_classifier_bow_prob=nb_classifier_bow.predict_proba(bow_test.iloc[:,:-1])[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81578947, 0.81320104, 0.80543572, 0.80500431, 0.81665229,\n",
       "       0.82484901, 0.82045749, 0.82175227, 0.81873112, 0.81355201])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_classifier_bow,bow_test.iloc[:,:-1],bow_test.iloc[:,-1],cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "676/676 [==============================] - 1s 922us/step - loss: 0.0297 - accuracy: 0.9157 - val_loss: 0.0109 - val_accuracy: 0.9795\n",
      "Epoch 2/8\n",
      "676/676 [==============================] - 1s 742us/step - loss: 0.0079 - accuracy: 0.9834 - val_loss: 0.0078 - val_accuracy: 0.9823\n",
      "Epoch 3/8\n",
      "676/676 [==============================] - 1s 748us/step - loss: 0.0064 - accuracy: 0.9860 - val_loss: 0.0069 - val_accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142b0d1d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model=Sequential()\n",
    "nn_model.add(Dense(100,input_dim=100,activation='relu'))\n",
    "nn_model.add(Dense(50,activation='relu'))\n",
    "nn_model.add(Dense(1,activation='sigmoid'))\n",
    "nn_model.compile(loss='mean_squared_logarithmic_error',optimizer='adam',metrics=['accuracy'])\n",
    "nn_model.fit(tfidf_train.iloc[:,:-1],tfidf_train.iloc[:,-1],epochs=8,batch_size=64,validation_split=0.2,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(min_delta=0.01,patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_prob=nn_model.predict(tfidf_test.iloc[:,:-1]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.9508 - val_loss: 0.0520 - val_accuracy: 0.9791\n",
      "Epoch 2/9\n",
      "338/338 [==============================] - 0s 950us/step - loss: 0.0389 - accuracy: 0.9745 - val_loss: 0.0318 - val_accuracy: 0.9764\n",
      "Epoch 3/9\n",
      "338/338 [==============================] - 0s 899us/step - loss: 0.0298 - accuracy: 0.9750 - val_loss: 0.0277 - val_accuracy: 0.9737\n",
      "Epoch 4/9\n",
      "338/338 [==============================] - 0s 914us/step - loss: 0.0270 - accuracy: 0.9752 - val_loss: 0.0261 - val_accuracy: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a058810>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_bow=Sequential()\n",
    "nn_model_bow.add(Dense(100,input_dim=100,activation='relu',kernel_regularizer='l2'))\n",
    "nn_model_bow.add(Dense(50,activation='relu',kernel_regularizer='l2'))\n",
    "nn_model_bow.add(Dense(1,activation='sigmoid',kernel_regularizer='l2'))\n",
    "nn_model_bow.compile(loss='mean_squared_logarithmic_error',optimizer='adam',metrics=['accuracy'])\n",
    "nn_model_bow.fit(bow_train.iloc[:,:-1],bow_train.iloc[:,-1],epochs=9,batch_size=128,validation_split=0.2,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(min_delta=0.01,patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_bow_prob=nn_model_bow.predict(bow_test.iloc[:,:-1]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def serialize_keras_model(model):\n",
    "    _, keras_file = tempfile.mkstemp('.h5')\n",
    "    tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "    print('Saved model to:', keras_file)\n",
    "\n",
    "    return keras_file\n",
    "\n",
    "def model_prunned(model,x,y,sparcity_target,batch,epoch):\n",
    "    saved_old_model=serialize_keras_model(model)\n",
    "    print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(saved_old_model)))\n",
    "    pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=sparcity_target,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=np.ceil(x.shape[0]/batch).astype(np.int32) * epoch)\n",
    "    }\n",
    "    prunned_model=tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "    prunned_model.compile(loss='mean_squared_logarithmic_error',optimizer='adam',metrics=['accuracy'])\n",
    "    callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    ]\n",
    "    prunned_model.fit(x, y,\n",
    "                      batch_size=batch, epochs=epoch,\n",
    "                      callbacks=callbacks)\n",
    "    ready_prunned_model=tfmot.sparsity.keras.strip_pruning(prunned_model)\n",
    "    \n",
    "    saved_prunned_model=serialize_keras_model(ready_prunned_model)\n",
    "    \n",
    "    print(\"Size of gzipped retrained pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(saved_prunned_model)))\n",
    "    return ready_prunned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: /var/folders/l7/12fq83gs45ddh1qrbf5mgwx00000gn/T/tmpo7oz44tq.h5\n",
      "Size of gzipped baseline Keras model: 59872.00 bytes\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Epoch 1/5\n",
      "423/423 [==============================] - 1s 1ms/step - loss: 0.0258 - accuracy: 0.9744\n",
      "Epoch 2/5\n",
      "423/423 [==============================] - 1s 1ms/step - loss: 0.0248 - accuracy: 0.9744\n",
      "Epoch 3/5\n",
      "423/423 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9747\n",
      "Epoch 4/5\n",
      "423/423 [==============================] - 1s 1ms/step - loss: 0.0243 - accuracy: 0.9744\n",
      "Epoch 5/5\n",
      "423/423 [==============================] - 1s 1ms/step - loss: 0.0242 - accuracy: 0.9741\n",
      "Saved model to: /var/folders/l7/12fq83gs45ddh1qrbf5mgwx00000gn/T/tmpyna6wnfu.h5\n",
      "Size of gzipped retrained pruned Keras model: 19560.00 bytes\n"
     ]
    }
   ],
   "source": [
    "prunned_model=model_prunned(nn_model_bow,bow_train.iloc[:,:-1],bow_train.iloc[:,-1],0.8,128,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /var/folders/l7/12fq83gs45ddh1qrbf5mgwx00000gn/T/tmpr8dukapt/assets\n",
      "Size of gzipped pruned and quantized TFlite model: 3979.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(prunned_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23176/23176 [00:48<00:00, 474.89it/s]\n"
     ]
    }
   ],
   "source": [
    "result_list=[]\n",
    "for i in tqdm(range(bow_test.shape[0])):\n",
    "    interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'],np.array(bow_test.iloc[i,:-1]).astype(np.float32).reshape((1,100)))\n",
    "    interpreter.invoke()\n",
    "    result_list.append(interpreter.get_tensor(interpreter.get_output_details()[0]['index'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean sqaured error between the prunned and quantinzed model and the original model is: 0.00034072148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "print('The mean sqaured error between the prunned and quantinzed model and the original model is:',\n",
    "      mean_squared_error(np.array(result_list),nn_model_bow_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15033\n",
       "1     8143\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_calc(model,truth,t):\n",
    "    temp_result=np.array(model)>t\n",
    "    return sum(temp_result[truth!=True])/sum(truth!=True)\n",
    "def fn_calc(model,truth,t):\n",
    "    temp_result=np.array(model)>t\n",
    "    return sum(temp_result[truth==True]!=True)/sum(truth==True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandwich Learned Bloom Filter Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(dataset,label_column_name,url_column_name,model_ouput,mem,backup,t):\n",
    "    \n",
    "\n",
    "    \"\"\"Initialize all the variables\"\"\"\n",
    "    all_pos_url=np.array(dataset[dataset[label_column_name]==1][url_column_name])\n",
    "    all_url=np.array(dataset[url_column_name])\n",
    "    label=np.array(dataset[label_column_name])\n",
    "\n",
    "    \"\"\"Initial Filter\"\"\"\n",
    "    initial_bf=BF.Bloom_Filter(mem-backup,len(all_pos_url))\n",
    "    for i in range(len(all_pos_url)):\n",
    "        initial_bf.insert(all_pos_url[i])\n",
    "\n",
    "    #run the data through initial bloom filter\n",
    "    round1_pos=[]\n",
    "    for i in range(len(all_url)):\n",
    "        if initial_bf.search(all_url[i])==True:\n",
    "            round1_pos.append(i)\n",
    "    #calculate the error rate of initial bf: False positive/All negatives\n",
    "    initial_err=(len(round1_pos)-len(all_pos_url))/(len(all_url)-len(all_pos_url))\n",
    "    print(initial_err)\n",
    "    print(initial_bf.false_pos)\n",
    "    \n",
    "    \"\"\"Classifier\"\"\"\n",
    "    #the data instance that are positive from initial filter and prob of 1 is bigger than T\n",
    "    positive_array=(model_ouput[round1_pos]>=t)\n",
    "\n",
    "    #creating backup filter and label variables\n",
    "    backup_filter_data=all_url[round1_pos][positive_array!=True]\n",
    "    backup_filter_label=label[round1_pos][positive_array!=True]\n",
    "    pos_backup_filter_data=[]\n",
    "    for i in range(len(backup_filter_data)):\n",
    "        if backup_filter_label[i]==True:\n",
    "            pos_backup_filter_data.append(backup_filter_data[i])\n",
    "    #calculating model accuracy\n",
    "    model_miss=sum(positive_array)-sum(label[round1_pos][positive_array])\n",
    "\n",
    "    model_false_pos=model_miss/(len(positive_array)-sum(positive_array))\n",
    "    neg_array=np.invert(positive_array)\n",
    "    neg_miss=sum(neg_array)-(len(label[round1_pos][neg_array])-sum(label[round1_pos][neg_array]))\n",
    "    model_false_neg=neg_miss/sum(model_ouput[round1_pos])\n",
    "    \"\"\"Backup Filter\"\"\"\n",
    "    backup_bf=BF.Bloom_Filter(backup,len(pos_backup_filter_data))\n",
    "    for i in range(len(pos_backup_filter_data)):\n",
    "        backup_bf.insert(pos_backup_filter_data[i])\n",
    "    \n",
    "    #run data through the backup filter \n",
    "    backup_bf_result=[]\n",
    "    backup_bf_truth=[]\n",
    "    for i in range(len(backup_filter_data)):\n",
    "        backup_bf_result.append(backup_bf.search(backup_filter_data[i]))\n",
    "        backup_bf_truth.append(backup_filter_label[i])\n",
    "\n",
    "    backup_err=(sum(backup_bf_result)-len(pos_backup_filter_data))/(len(backup_filter_data)-len(pos_backup_filter_data))\n",
    "\n",
    "    \"\"\"Total Error Rate\"\"\"\n",
    "    #initial_miss=len(round1_pos)-len(all_pos_url)\n",
    "    backup_miss=sum(backup_bf_result)-len(pos_backup_filter_data)\n",
    "    total_err=(model_miss+backup_miss)/(len(all_url)-len(all_pos_url))\n",
    "    #=============================================================================\n",
    "    #0.6185 is calculated based on false pos rate=p^k=p^(ln2*(m/2)) where p is % of bits that are 0 after hashed and when p=0.5, p^ln2=0.6185\n",
    "    #ideal_total_err=(0.6185**(initial_bf.array_size/initial_bf.length))*(model_false_pos+(1-model_false_pos)*(0.6185**((backup_bf.array_size/backup_bf.length))))\n",
    "\n",
    "    return total_err#backup_bf.false_pos,initial_err,initial_bf.false_pos,backup_err,backup_bf.false_pos, total_err,ideal_total_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002535869202535869"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use TFIDF+Neural Network\n",
    "filter(tfidf_input,'label','url',nn_model_prob,20000,3000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39039039039039036"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use TFIDF+NB Classifier\n",
    "filter(tfidf_input,'label','url',nb_classifier_prob,20000,3000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3796438337891016\n",
      "0.3820532196532891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03581671446675115"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use BOW+ Compressed NN\n",
    "filter(bow_input,'label','url',compressed_nn_bow_prob,20000,3000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032548522643900485"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use BOW+ NN\n",
    "filter(bow_input,'label','url',nn_model_bow_prob,20000,3000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012005602614553459"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use BOW+NB Classifier\n",
    "filter(bow_input,'label','url',nb_classifier_bow_prob,80000,3000,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloom_filter(size,data,label_column,url_column):\n",
    "    labels=np.array(data[label_column])\n",
    "    all_data=np.array(data[url_column])\n",
    "    pos_data=np.array(data.loc[data[label_column]==1,url_column])\n",
    "    \n",
    "    bf=BF.Bloom_Filter(size,len(pos_data))\n",
    "    for i in range(len(pos_data)):\n",
    "        bf.insert(pos_data[i])\n",
    "\n",
    "    #run the data through initial bloom filter\n",
    "    pos=[]\n",
    "    for i in range(len(all_data)):\n",
    "        if bf.search(all_data[i])==True:\n",
    "            pos.append(i)\n",
    "    #calculate the error rate of initial bf: False positive/All negatives\n",
    "    err=(len(pos)-len(pos_data))/(len(all_data)-len(pos_data))\n",
    "    return err,bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2320228829907537, <Bloom_filters_test.Bloom_Filter at 0x12b38b490>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_filter(25000,bow_input,'label','url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 1312.82it/s]\n"
     ]
    }
   ],
   "source": [
    "def experiment(mem):\n",
    "    error=[]\n",
    "    error.append([filter(bow_input,'label','url',compressed_nn_bow_prob,mem,3000,0.5),\n",
    "                filter(bow_input,'label','url',nn_model_bow_prob,mem,3000,0.5),\n",
    "                bloom_filter(mem,bow_input,'label','url')])\n",
    "    return error\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    p=multiprocessing.Pool(processes=6)\n",
    "    total_error=p.map(experiment,tqdm([i for i in np.arange(10000,100000,5000)]))\n",
    "    p.close()\n",
    "\n",
    "total_error=np.array(total_error).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.56134530600863"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp=fp_calc(compressed_nn_bow_prob,bow_test['Label'],0.6)\n",
    "fn=fn_calc(compressed_nn_bow_prob,bow_test['Label'],0.6)\n",
    "loc=(math.log(np.average(0.01)/((1-np.average(0.01))*((1/np.average(fn))-1)))/math.log(0.6185))\n",
    "loc/fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7861, 8183)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(compressed_nn_bow_prob>0.2),sum(bow_test['Label']!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# for i in range(len(total_error)):\n",
    "ax.plot(np.arange(10000+4287,100000+4287,5000),total_error[0][0], ms=20, label='Compressed NN SLBF')\n",
    "ax.plot(np.arange(10000+59958,100000+59958,5000),total_error[1][0], ms=20, label='Regular Size SLBF')\n",
    "ax.plot(np.arange(10000,100000,5000),total_error[2][0],  ms=20, label='Regular BF')\n",
    "    \n",
    "\n",
    "# loc=(math.log(np.average(fp)/((1-np.average(fp))*((1/np.average(fn))-1)))/math.log(0.6185))\n",
    "ax.hlines(0.05,xmin=10000,xmax=160000,linestyle='dotted', label='False Positive Rate of 0.05')\n",
    "# ax.set_ylim([0,0.004])\n",
    "# ax.plot(np.arange(1.0,0.1,-0.01),ideal_backup_err_array, linestyle='solid', ms=15, label='Back Up Filter Error Rate')\n",
    "# ax.plot(np.arange(0.1,1.0,0.01),model_error_array, linestyle='dashdot', ms=15, label='Model Error Rate')\n",
    "#ax.plot(np.arange(0,1.0,0.01),err_result_array, linestyle='dashdot', ms=15, label='Initial Filter Error Rate')\n",
    "# ax.set_xlabel('Threshold Value')\n",
    "# ax.set_ylabel('Model Error Rate')\n",
    "ax.legend(loc=1,fontsize=8)\n",
    "# ax2=ax.twinx()\n",
    "# ax2.plot(np.arange(0.1,0.9,0.01),pos_count_array, linestyle='dashdot', ms=15, label='Predicted Positive Count')\n",
    "# ax2.plot(np.arange(0.1,0.9,0.01),neg_count_array, linestyle='dashdot', ms=15, label='Predicted Negative Count')\n",
    "# ax2.plot(np.arange(0.1,0.9,0.01),pos_truth_array, linestyle='solid', ms=15, label='Real Positive Count')\n",
    "# ax2.plot(np.arange(0.1,0.9,0.01),neg_truth_array, linestyle='solid', ms=15, label='Real Negative Count')\n",
    "# ax2.set_ylabel('Count')\n",
    "# ax2.legend(loc=7,fontsize=8)\n",
    "# ax.plot(np.arange(5000,20000,500),gradient, linestyle='dashdot', ms=15)\n",
    "plt.xlabel('Total Memory')\n",
    "plt.ylabel('Total False Positive Rate')\n",
    "# plt.ylabel('Error Rate')\n",
    "plt.title('Total Memory vs Total Positive Rate with Different Structure')\n",
    "plt.savefig('result.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1():\n",
    "    filter(bow_input,'label','url',compressed_nn_bow_prob,20000,3000,0.5)\n",
    "def f2():\n",
    "    bloom_filter(4287+20000,bow_input,'label','url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.730113495000069\n",
      "4.82069439299994\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "if __name__ == \"__main__\": \n",
    "    print(timeit.timeit(f1, number=100))\n",
    "    print(timeit.timeit(f2, number=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import SLBF module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLBF import SLBF\n",
    "\n",
    "slbf=SLBF()\n",
    "slbf.construct(bow_input,'label','url',quantized_and_pruned_tflite_model,bow_test,20000,3000,0.5)\n",
    "\n",
    "slbf.search(bow_input['url'][0],np.array(bow_test.iloc[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization Time for SLBF:  27.50821524899993\n",
      "Initialization Time for Bloom Filter:  0.06165344400005779\n"
     ]
    }
   ],
   "source": [
    "def f1():\n",
    "    slbf=SLBF()\n",
    "    slbf.construct(bow_input,'label','url',quantized_and_pruned_tflite_model,bow_test,20000,3000,0.5)\n",
    "def f2():\n",
    "    bloom_filter(4287+20000,bow_input,'label','url')\n",
    "    \n",
    "import timeit\n",
    "if __name__ == \"__main__\": \n",
    "    print('Initialization Time for SLBF: ',timeit.timeit(f1, number=1))\n",
    "    print('Initialization Time for Bloom Filter: ',timeit.timeit(f2, number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization Time for SLBF:  1.8075016550001237\n",
      "Initialization Time for Bloom Filter:  0.011005262000253424\n"
     ]
    }
   ],
   "source": [
    "def f1():\n",
    "    slbf.search(bow_input['url'][0],np.array(bow_test.iloc[0,:]))\n",
    "\n",
    "err,bf=bloom_filter(4287+20000,bow_input,'label','url')\n",
    "def f2():\n",
    "    bf.search(bow_input['url'][0])\n",
    "    \n",
    "import timeit\n",
    "if __name__ == \"__main__\": \n",
    "    print('Searching Time for SLBF: ',timeit.timeit(f1, number=1000))\n",
    "    print('Searching Time for Bloom Filter: ',timeit.timeit(f2, number=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
